{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 tables - Beautiful Soup vs LXML\n",
    "1. total time\n",
    "2. process time\n",
    "3. memory usage\n",
    "4. data usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Total Time Taken - beautifulsoup: 0.8521325588226318 sec\n",
      "Avg Process Time Taken - beautifulsoup: 0.2725 sec\n",
      "Total time taken to iterate through 50 pages - beautifulsoup: 42.60862112045288 sec\n"
     ]
    }
   ],
   "source": [
    "def getHTMLdocument(url):\n",
    "      \n",
    "        response = requests.get(url)      \n",
    "        return response.text\n",
    "\n",
    "rownum = 0\n",
    "book_table = pd.DataFrame(columns=[\"Sr. No.\", \"Name\", \"Link\", \"Cost\", \"Availability\"])\n",
    "total_time_bs = []\n",
    "process_time_bs = []\n",
    "over_all_pages_start_bs = time.time()\n",
    "\n",
    "for j in range(1, 51):\n",
    "        start_time_bs = time.process_time()\n",
    "        start_time_total_bs = time.time()\n",
    "\n",
    "        url_to_scrape = \"http://books.toscrape.com/catalogue/page-\" + str(j) + \".html\"  \n",
    "        html_document = getHTMLdocument(url_to_scrape)  \n",
    "        soup = BeautifulSoup(html_document, 'html.parser')\n",
    "\n",
    "\n",
    "        for row in soup.find_all('li', attrs={'class': re.compile(\"col-xs-6\")}):\n",
    "\n",
    "                rownum += 1\n",
    "                name = row.find('h3').find('a').get('title')\n",
    "                link = \"http://books.toscrape.com/catalogue/\" + row.find('h3').find('a').get('href')\n",
    "                cost = row.find('p', attrs = {'class': re.compile(\"price_color\")}).text.strip()\n",
    "                cost = cost[2:]\n",
    "                availability = row.find('p', attrs = {'class': re.compile(\"instock availability\")}).text.strip()        \n",
    "                book_table.loc[len(book_table.index)] = [rownum, name, link, cost, availability ] \n",
    "\n",
    "        stop_time_bs = time.process_time()\n",
    "        stop_time_total_bs = time.time()\n",
    "\n",
    "        tt = stop_time_total_bs - start_time_total_bs\n",
    "        pt = stop_time_bs - start_time_bs\n",
    "\n",
    "        total_time_bs.append(tt)\n",
    "        process_time_bs.append(pt)\n",
    "\n",
    "over_all_pages_stop_bs = time.time()\n",
    "\n",
    "print(f\"Avg Total Time Taken - beautifulsoup: {sum(total_time_bs)/len(total_time_bs)} sec\")\n",
    "print(f\"Avg Process Time Taken - beautifulsoup: {sum(process_time_bs)/len(process_time_bs)} sec\")\n",
    "print(f\"Total time taken to iterate through 50 pages - beautifulsoup: {over_all_pages_stop_bs-over_all_pages_start_bs} sec\")\n",
    "\n",
    "book_table.to_excel('py_request_bs.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Total Time Taken - lxml: 0.8434636974334717 sec\n",
      "Avg Process Time Taken - lxml: 0.26875 sec\n",
      "Total time taken to iterate through 50 pages - lxml: 42.173184871673584 sec\n"
     ]
    }
   ],
   "source": [
    "''' LXML '''\n",
    "\n",
    "def getHTMLdocument(url):      \n",
    "        response = requests.get(url)      \n",
    "        return response.content\n",
    "\n",
    "rownum = 0\n",
    "book_table_lxml = pd.DataFrame(columns=[\"Sr. No.\", \"Name\", \"Link\", \"Cost\", \"Availability\"])\n",
    "total_time_lxml = []\n",
    "process_time_lxml = []\n",
    "over_all_pages_start_lxml = time.time()\n",
    "\n",
    "for j in range(1,51):\n",
    "        start_time_lxml = time.process_time()\n",
    "        start_time_total_lxml = time.time()\n",
    "\n",
    "        url = \"http://books.toscrape.com/catalogue/page-\" + str(1) + \".html\"\n",
    "        byte_data = getHTMLdocument(url)\n",
    "        source_code = html.fromstring(byte_data)\n",
    "        \n",
    "        for i in range(1,21):\n",
    "\n",
    "                rownum += 1\n",
    "                name_path = '//*[@id=\"default\"]/div/div/div/div/section/div[2]/ol/li[' + str(i) + ']/article/h3/a/@title' \n",
    "                book_link_path = '//*[@id=\"default\"]/div/div/div/div/section/div[2]/ol/li[' + str(i) + ']/article/h3/a/@href'\n",
    "                cost_path = '//*[@id=\"default\"]/div/div/div/div/section/div[2]/ol/li[' + str(i) + ']/article/div[2]/p[1]' \n",
    "                stock_path = '//*[@id=\"default\"]/div/div/div/div/section/div[2]/ol/li[' + str(i) + ']/article/div[2]/p[2]' \n",
    "\n",
    "                name = source_code.xpath(name_path)[0]\n",
    "                book_link = \"http://books.toscrape.com/catalogue/\" + source_code.xpath(book_link_path)[0]\n",
    "                cost = source_code.xpath(cost_path)[0].text_content()\n",
    "                stock = source_code.xpath(stock_path)[0].text_content().strip()\n",
    "\n",
    "                book_table_lxml.loc[len(book_table_lxml.index)] = [rownum, name, book_link, cost, stock ]\n",
    "\n",
    "        stop_time_lxml = time.process_time()\n",
    "        stop_time_total_lxml = time.time()\n",
    "\n",
    "        tt = stop_time_total_lxml - start_time_total_lxml\n",
    "        pt = stop_time_lxml - start_time_lxml\n",
    "\n",
    "        total_time_lxml.append(tt)\n",
    "        process_time_lxml.append(pt)\n",
    "\n",
    "over_all_pages_stop_lxml = time.time()\n",
    "\n",
    "print(f\"Avg Total Time Taken - lxml: {sum(total_time_lxml)/len(total_time_lxml)} sec\")\n",
    "print(f\"Avg Process Time Taken - lxml: {sum(process_time_lxml)/len(process_time_lxml)} sec\")\n",
    "print(f\"Total time taken to iterate through 50 pages - lxml: {over_all_pages_stop_lxml-over_all_pages_start_lxml} sec\")\n",
    "\n",
    "book_table_lxml.to_excel('py_request_lxml.xlsx', index = False)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting in EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = pd.DataFrame(columns=['Sr. No.', 'bs4', 'LXML'])\n",
    "process_time = pd.DataFrame(columns = ['Sr. No.', 'bs4', 'LXML'])\n",
    "\n",
    "for i in range(0,50):\n",
    "    num = i + 1\n",
    "    total_time.loc[len(total_time.index)] = [int(num), total_time_bs[i], total_time_lxml[i]]\n",
    "    process_time.loc[len(process_time.index)] = [int(num), process_time_bs[i], process_time_lxml[i]]\n",
    "\n",
    "total_time.to_csv('Over_50_url_total_time.csv', index = False)\n",
    "process_time.to_csv('Over_50_url_process_time.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bceec554de280a03412a6f09a63c4022cb2fe8fc3df3020533e7e5739cca0ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
